{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ee412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8ecedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enterprise Data Science ML Pipeline for Bank Telemarketing (bank-additional-full.csv)\n",
    "# Author: ChatGPT (GPT-5 Thinking mini)\n",
    "# Purpose: End-to-end reproducible ML pipeline (no neural nets, no SVMs)\n",
    "# Instructions: place this file in the same folder as 'bank-additional-full.csv' and run in a Python environment (conda/venv)\n",
    "\n",
    "# %% Imports\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, confusion_matrix, classification_report, roc_curve, auc)\n",
    "import joblib\n",
    "\n",
    "# Optional: SHAP for interpretation\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except Exception:\n",
    "    SHAP_AVAILABLE = False\n",
    "\n",
    "# %% User-configurable parameters\n",
    "CSV_PATH = '../data/01-bronze/bank-additional-full.csv'  # adjust path if needed\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "CV_FOLDS = 5\n",
    "SAMPLE_FRACTION = None  # set to <1.0 if you want to run a quick experiment\n",
    "\n",
    "# %% Utility functions\n",
    "\n",
    "def load_data(path=CSV_PATH, sample_fraction=None):\n",
    "    \"\"\"Load CSV using semicolon separator used by this dataset.\"\"\"\n",
    "    df = pd.read_csv(path, sep=';')\n",
    "    if sample_fraction is not None and 0 < sample_fraction < 1.0:\n",
    "        df = df.sample(frac=sample_fraction, random_state=RANDOM_STATE)\n",
    "    return df\n",
    "\n",
    "\n",
    "def basic_cleaning(df):\n",
    "    \"\"\"Basic cleaning: strip column names, lowercase, map target to binary.\"\"\"\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    # target\n",
    "    if 'y' in df.columns:\n",
    "        df['y'] = df['y'].map({'yes': 1, 'no': 0}).astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_feature_lists(df):\n",
    "    \"\"\"Return lists of numerical and categorical columns for the dataset.\"\"\"\n",
    "    # from dataset documentation, some columns should be numeric\n",
    "    num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    if 'y' in num_cols:\n",
    "        num_cols.remove('y')\n",
    "    # treat some numeric-like columns as categorical if needed\n",
    "    cat_cols = [c for c in df.columns if c not in num_cols + ['y']]\n",
    "    return num_cols, cat_cols\n",
    "\n",
    "\n",
    "def evaluate_model(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred_proba = None\n",
    "    if hasattr(clf, 'predict_proba'):\n",
    "        y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "    elif hasattr(clf, 'decision_function'):\n",
    "        y_pred_proba = clf.decision_function(X_test)\n",
    "\n",
    "    metrics = {}\n",
    "    metrics['accuracy'] = accuracy_score(y_test, y_pred)\n",
    "    metrics['precision'] = precision_score(y_test, y_pred)\n",
    "    metrics['recall'] = recall_score(y_test, y_pred)\n",
    "    metrics['f1'] = f1_score(y_test, y_pred)\n",
    "    if y_pred_proba is not None:\n",
    "        metrics['roc_auc'] = roc_auc_score(y_test, y_pred_proba)\n",
    "    else:\n",
    "        metrics['roc_auc'] = None\n",
    "    metrics['confusion_matrix'] = confusion_matrix(y_test, y_pred)\n",
    "    metrics['classification_report'] = classification_report(y_test, y_pred)\n",
    "    return metrics, y_pred_proba\n",
    "\n",
    "\n",
    "def lift_score(y_true, y_proba, top_pct=0.1):\n",
    "    \"\"\"Compute uplift/lift metric: ratio of positive rate in top_pct predicted vs overall.\"\"\"\n",
    "    df = pd.DataFrame({'y': y_true, 'p': y_proba})\n",
    "    df_sorted = df.sort_values('p', ascending=False)\n",
    "    cutoff = int(len(df_sorted) * top_pct)\n",
    "    top = df_sorted.head(cutoff)\n",
    "    uplift = (top['y'].mean() / df['y'].mean()) if df['y'].mean() > 0 else np.nan\n",
    "    return uplift\n",
    "\n",
    "# %% Main pipeline builder\n",
    "\n",
    "def build_preprocessor(num_cols, cat_cols):\n",
    "    num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', num_pipeline, num_cols),\n",
    "        ('cat', cat_pipeline, cat_cols)\n",
    "    ], remainder='drop', verbose_feature_names_out=False)\n",
    "    return preprocessor\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# %% Model candidates + hyperparameter grids\n",
    "\n",
    "def get_models_and_grids():\n",
    "    models = {\n",
    "        'logistic': LogisticRegression(solver='liblinear', class_weight='balanced', random_state=RANDOM_STATE),\n",
    "        'decision_tree': DecisionTreeClassifier(random_state=RANDOM_STATE, class_weight='balanced'),\n",
    "        'random_forest': RandomForestClassifier(n_jobs=-1, random_state=RANDOM_STATE, class_weight='balanced'),\n",
    "        'xgboost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_jobs=-1, random_state=RANDOM_STATE)\n",
    "    }\n",
    "\n",
    "    grids = {\n",
    "    'logistic': {\n",
    "        'clf__C': [0.01, 0.1, 1.0, 10.0, 50.0, 100.0],\n",
    "        'clf__penalty': ['l1', 'l2'],  # L1 = sparsity, L2 = standard\n",
    "        'clf__solver': ['liblinear', 'saga']  # saga allows l1/l2 with larger datasets\n",
    "    },\n",
    "    'decision_tree': {\n",
    "        'clf__max_depth': [3, 5, 10, 15, None],\n",
    "        'clf__min_samples_leaf': [1, 2, 5, 10, 20],\n",
    "        'clf__min_samples_split': [2, 5, 10, 20],\n",
    "        'clf__max_features': [None, 'sqrt', 'log2']\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'clf__n_estimators': [100, 300, 500],\n",
    "        'clf__max_depth': [5, 10, 15, None],\n",
    "        'clf__min_samples_split': [2, 5, 10],\n",
    "        'clf__min_samples_leaf': [1, 2, 5, 10],\n",
    "        'clf__max_features': ['sqrt', 'log2', None],\n",
    "        'clf__bootstrap': [True, False]\n",
    "    },\n",
    "    'xgboost': {\n",
    "        'clf__n_estimators': [100, 300, 500],\n",
    "        'clf__max_depth': [3, 5, 6, 8],\n",
    "        'clf__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'clf__subsample': [0.6, 0.8, 1.0],\n",
    "        'clf__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'clf__gamma': [0, 0.1, 0.2],\n",
    "        'clf__reg_alpha': [0, 0.01, 0.1],\n",
    "        'clf__reg_lambda': [1, 1.5, 2]\n",
    "    }}\n",
    "    return models, grids\n",
    "\n",
    "# %% Orchestrator: trains CV + returns best estimator per model\n",
    "\n",
    "def run_model_selection(X_train, y_train, preprocessor, models, grids, cv=CV_FOLDS):\n",
    "    best_estimators = {}\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=RANDOM_STATE)\n",
    "    for name, model in tqdm(models.items(), desc='Model Selection', total=len(models)):\n",
    "        print(f\"\\nTraining and tuning: {name}\")\n",
    "        pipe = Pipeline([\n",
    "            ('pre', preprocessor),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "        param_grid = grids.get(name, {})\n",
    "        gs = GridSearchCV(pipe, param_grid=param_grid, scoring='roc_auc', cv=skf, n_jobs=1, verbose=2)\n",
    "        gs.fit(X_train, y_train)\n",
    "        print(f\"Best {name} score: {gs.best_score_:.4f}\")\n",
    "        print(f\"Best params: {gs.best_params_}\")\n",
    "        best_estimators[name] = gs.best_estimator_\n",
    "    return best_estimators\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# %% Run everything (main)\n",
    "if __name__ == '__main__':\n",
    "    print('Loading data...')\n",
    "    if not os.path.exists(CSV_PATH):\n",
    "        raise FileNotFoundError(f\"CSV not found at {CSV_PATH}. Please place the dataset in the working directory or update CSV_PATH.\")\n",
    "\n",
    "    df = load_data(CSV_PATH, sample_fraction=SAMPLE_FRACTION)\n",
    "    df = basic_cleaning(df)\n",
    "\n",
    "    print('Preparing feature lists...')\n",
    "    num_cols, cat_cols = get_feature_lists(df)\n",
    "    print(f'Numerical columns ({len(num_cols)}): {num_cols}')\n",
    "    print(f'Categorical columns ({len(cat_cols)}): {cat_cols}')\n",
    "\n",
    "    # Optional: drop 'duration' if you want a realistic pre-call model (duration is only known after call)\n",
    "    if 'duration' in df.columns:\n",
    "        print('\\nRemoving `duration` from features for realistic pre-call predictions (recommended).')\n",
    "        df = df.drop(columns=['duration'])\n",
    "        num_cols, cat_cols = get_feature_lists(df)\n",
    "\n",
    "    X = df.drop(columns=['y'])\n",
    "    y = df['y']\n",
    "\n",
    "    print('Splitting train/test')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE,\n",
    "                                                        stratify=y, random_state=RANDOM_STATE)\n",
    "\n",
    "    preprocessor = build_preprocessor(num_cols, cat_cols)\n",
    "    models, grids = get_models_and_grids()\n",
    "\n",
    "    best_estimators = run_model_selection(X_train, y_train, preprocessor, models, grids)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    results = {}\n",
    "    for name, est in best_estimators.items():\n",
    "        print(f\"\\nEvaluating best {name} on test set\")\n",
    "        metrics, y_proba = evaluate_model(est, X_test, y_test)\n",
    "        # compute lift\n",
    "        if y_proba is not None:\n",
    "            metrics['lift_top_10pct'] = lift_score(y_test.reset_index(drop=True), y_proba, top_pct=0.10)\n",
    "        results[name] = metrics\n",
    "        print(metrics['classification_report'])\n",
    "        print('ROC AUC:', metrics['roc_auc'])\n",
    "        print('Lift (top 10%):', metrics.get('lift_top_10pct'))\n",
    "\n",
    "    # Choose final model (e.g., best ROC AUC on test)\n",
    "    best_name = max(results.items(), key=lambda kv: (kv[1]['roc_auc'] or 0))[0]\n",
    "    final_model = best_estimators[best_name]\n",
    "    print(f\"\\nSelected final model: {best_name}\")\n",
    "\n",
    "    # Save final model\n",
    "    joblib.dump(final_model, f'final_model_{best_name}.joblib')\n",
    "    print(f\"Final model saved to final_model_{best_name}.joblib\")\n",
    "\n",
    "    # Optional: SHAP explainability\n",
    "    if SHAP_AVAILABLE:\n",
    "        print('\\nComputing SHAP values for final model (may take time)...')\n",
    "        # We need the preprocessed matrix for SHAP\n",
    "        X_train_transformed = final_model.named_steps['pre'].transform(X_train)\n",
    "        # For tree models use TreeExplainer\n",
    "        explainer = shap.TreeExplainer(final_model.named_steps['clf'])\n",
    "        shap_values = explainer.shap_values(X_train_transformed)\n",
    "        shap.summary_plot(shap_values, X_train_transformed)\n",
    "    else:\n",
    "        print('\\nSHAP not available. To enable, `pip install shap`.')\n",
    "\n",
    "    print('\\nPipeline complete. Review results dictionary `results` for full metrics.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6bc3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573d1a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(results, width=120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
